The CMS \cite{CMS} experiment at the LHC has recently successfully concluded it's first run. 
Between the fall of 2010 and the spring of 2013, over 10 billion raw data events were recorded, 
and 15 billion monte-carlo events produced. The data were analysed using the distributed resources 
of CMS, managed through the Worldwide LHC Computing Grid (WLCG) \cite{WLCG} and through the CMS 
dataflow and workflow management tools.

The operational aspects of the CMS computing system are described separately \cite{OliOps}. In 
this paper we describe the performance of the CMS data management system during run 1. We describe 
what worked well and what didn't, and analyse the factors that contributed to the performance. 
Finally, we describe the improvements planned in the major subsystems for the second run of LHC, 
starting in 2015.
