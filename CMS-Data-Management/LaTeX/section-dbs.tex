%!TEX root = chep2013_CMS-Data-Management.tex
The Data Bookkeeping Service (DBS) \cite{DBS} provides a catalogue of event metadata for Monte Carlo and recorded data of the CMS experiment. DBS contains record of what data exist, their process-oriented provenance information, including parentage relationships of files and datasets, their configurations of processing steps, as well as associations with run numbers and luminosity sections to find any particular subset of events within a dataset, on a large scale of about $200,000$ datasets and more than $40$ million files, which adds up to around $700$ GB of metadata.

The current DBS, DBS~2 \cite{DBS2} was designed in 2006-2007, before the LHC started its operation. CMS did not have a standardised service architecture for the implementation, deployment and operation of that kind of web services. Thus DBS~2 was implemented using Java servlets in an Apache Tomcat container and XML RPC has been the first choice for the client-server communication. As  persistent storage system of the metadata, an Oracle database backend provided for CMS \cite{CMSDBs} is utilised. DBS~2 additionally supports a MySQL database backend, however it is currently not used in the production environment.

The DBS is a federated system with multiple instances for different scopes. Driven by the principle in CMS to separate official and user-created data, the Global-DBS contains metadata related to all official CMS data, real or simulated. Metadata related to user-created datasets can be stored in two physics analysis DBS instances. Besides those instances there are also a CAF instance, that records data from the prompt reconstruction stream used for detector calibrations and diagnostics, and a CMS Tier0 DBS instance, that records information for data from the detector as it is processed by the Tier0 facility.

Although DBS~2 sustained the load in LHC Run $1$, it has in some cases very ``thick'' client APIs, which  led to numerous problems with API versioning and scalability issues. In addition, the CMS data processing model has evolved a lot, in a way that could not be anticipated by the DBS~2 design back in $2006$, so many requests were made to store additional data in DBS~2, which were not entirely consistent with its original purpose. A project review in $2009$ led to the decision to re-design DBS, to better match the CMS data processing model and to better integrate with the DMWM projects.

The CMS DMWM project has meanwhile developed a standardised architecture based on the Representational State Transfer API (REST) \cite{REST} for its web services based on Python, CherryPy and SQLAlchemy. Thus DBS~3 has been re-designed and re-implemented in Python utilizing the CMS DMWM standards for RESTful web services. The client-server communication is stateless and REST also imposes the discipline of thin clients, which enhances the scalability of the service. The Java Script Object Notation (JSON) is used as data-format for the client-server communication being a lightweight replacement for XML RPC. The database schema of DBS~3 also has been revised, based on the experiences with DBS~2. The schema has been denormalised, since the DBS~2 schema was fully normalised, leading to excessive table joins and lock contention. In DBS~3 some tables were removed, as well as some relationships that were better modeled outside of the DBS schema. These changes sped up searches and also improved the insertion of data by removing foreign keys and lock contention. In addition, the DBS~3 particularly benefitted from the narrower and more precise project scope compared to DBS~2. The integration with other services (PhEDEx and DAS) in the CMS DMWM project made a narrower scope possible, without impairing the query features, so for example the data location is not anymore stored in DBS, since it is naturally available from PhEDEx. DBS~3 is currently deployed in parallel to DBS~2 for validation and integration with other DMWM projects. The final switch to DBS~3 is expected by the end of $2013$.

