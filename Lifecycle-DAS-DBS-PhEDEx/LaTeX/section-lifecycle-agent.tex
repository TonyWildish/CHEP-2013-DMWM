\subsection{Architecture}
The LifeCycle agent emulates the actions of users or external processes in 
a system. The key abstraction is the {\it workflow}, which consists of a sequence of {\it events} 
that depend on each other and are performed at distinct intervals. A sample workflow for PhEDEx could consist of the following events:

\begin{itemize}
  \item Generate data - a dataset is generated with a set of files.
  \item The files are `injected' (registered) into PhEDEx at a given site.
  \item The datasets are subscribed for transfer to one or more other sites.
  \item After a time, the data may be deleted from one or more of the sites.
\end{itemize}

By varying the details of how the generated data is organised, which sites it is sent to, and 
which sites (if any) it is finally deleted from, we can emulate different real-life situations.

Many workflows can run in parallel. We can emulate the production of dozens of 
datasets, each destined for different sites, each with different characteristics, to give us a 
realistic emulation of the total workload of the production transfer system.

\subsection{Event handlers}
Each workflow has an array of {\it events}. This is an array of strings which the agent maps to their handlers. Handlers can be Perl modules loaded at runtime, or external scripts written in any language.

To use an external script as a handler, it must accept two filename arguments, one for input and one for output. The LifeCycle agent packages the workflow as a JSON object, writes it to the input file, then calls the script. The script reads the file and reconstitutes the object in it's own representation (e.g. a python dictionary), then accesses the elements it needs to do its work. When the script finishes it re-packages the workflow and writes it to the output file, which the LifeCycle agent will read and use to update its internal representation of the workflow.

Workflows are processed in parallel. As soon as one event-handler for a workflow finishes, the next event for that workflow is queued, for execution after a configurable delay. External script handlers are run asynchronously, handlers written as Perl modules can be either synchronous or asynchronous. A workflow completes when its last event has been processed. After that, depending on the configuration for that workflow, it can be restarted again at a later time.

Mechanisms are provided for event handlers to signal errors to abort the workflow or the entire LifeCycle agent, or to provide statistics that are accumulated by the agent and reported periodically.

Workflows need not be fixed. The event handler has access to the entire workflow object and can manipulate the event chain in many ways. It can re-insert the current event, to block the workflow, polling for an external condition to be satisfied. It can append events to the event chain, to steer the workflow according to the conditions it has encountered so far. Handlers can even spawn new workflows, by cloning and modifying their own workflow.